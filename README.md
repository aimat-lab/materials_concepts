# Dataset Creation

## Create data/ folder

Create `data/` top-level folder.

## Data Fetching

Fetch all related sources: (`--folder data/` can be omitted)

`$ python downloader/download_sources.py 'materials science' --folder data/`

> This will create a `data/materials-science.sources.csv` file with all the sources.

Fetch works from single source:

`$ python downloader/download_works.py S82336448 --folder data/`

> This will create a `data/S82336448.csv` file with all the works belonging to that source.

Fetch works from all sources:

`$ python downloader/download_works.py data/materials-science.sources.csv --folder data/`

> During fetching, this will create a `{source}.csv` file for each source in `{folder}/` listing all the works which belong to that source. After downloading, these are merged automatically into a single file `materials-science.works.csv` in the specified folder.
> If the download gets interrupted, the downloaded files serve as a cache. Re-run the script, it will automatically skip sources for which the data was already fetched.

## Data Filtering

Filter the data to improve its quality:

`$ python filtering/filter_works.py materials-science.works.csv --folder data/`

> This will output a file `materials-science.filtered.works.csv` in the specified folder containing all works which sufficed the conditions.

## Data Preparation

### Cleaning abstracts

Clean the abstracts:

`$ python preparation/clean_abstracts.py materials-science.filtered.works.csv --folder data/`

> This will output a file `materials-science.cleaned.works.csv` in the specified folder containing all works with cleaned abstracts.

### Extraction

> Note: As these operations are very time consuming, they are split across several scripts and parallelized. The scripts should be run in the following order:

1. Extract 'chemical elements' from abstracts:

`$ python preparation/extract_elements.py materials-science.cleaned.works.csv --folder data/`

> This will output a file `materials-science.elements.works.csv` in the specified folder containing all works with extracted chemical elements in a separate columns `elements`.

2. Extract 'concepts' from abstracts:

`$ python preparation/extract_concepts.py materials-science.elements.works.csv {method} {colname} --folder data/`

e.g.:

`$ python preparation/extract_concepts.py materials-science.elements.works.csv rake rake_concepts --folder data/`

> This will output a file `materials-science.rake.works.csv` in the specified folder containing all works with extracted concepts according to `rake` (`{method}`) in a separate columns `rake_concepts` (`{colname}`).

**Note:** The concepts currently used are generated by utilizing a LLM (LLaMa-13B). They are stored in `data/concepts.csv` and can be joined on `ID` column.

# Classification

## Build Graph

Build concepts graph by executing the following command:

```
python graph/build.py \
  --input_path data/table/materials-science.llama.works.csv \
  --output_path data/graph/edges_small.pkl \
  --lookup_path data/table/lookup/lookup_small.csv \
  --colname llama_concepts \
  --min_occurence 3 \
  --min_words 3 \
  --max_words 10 \
  --min_occurence_elements 3 \
  --min_amount_elements 2
```

Produces a pickled file `graph/edges.pkl` containing the graph:

```
{
  "num_of_vertices": 123456,
  "edges": [(v1, v2, timestamp), (v1, v2, timestamp), ...],
}
```

Because of the sparse nature of the graph, it is stored as edge list. The timestamp is the number of days passed since `01-01-1970`.

> Note: If you want use rake concepts, you have to first extract the rake concepts and then replace `llama_concepts` with `rake_concepts` in the command above.

> Note: The concepts are run against a filter mechanism to remove concepts which are not relevant for the domain. The filters are stored in the same file and can be extended or modified as needed.

## Generate Raw Classification Task Data

Generate training and test data for classification task: Given {n} vertex pairs, decide whether they will be connected or not in {delta} years.

```
python model/create_data.py \
 --graph_path data/graph/edges.pkl \
 --data_path data/model/data.pkl \
 --year_start_train 2016 \
 --year_start_test 2019 \
 --year_delta 3 \
 --edges_used_train 4_000_000 \
 --edges_used_test 2_000_000 \
 --min_links 1 \
 --max_v_degree=None \
 --verbose=True
```

Output:

```
{
  "year_train": 2016,
  "year_test": 2019,
  "year_delta": 3,
  "min_links": 1,
  "max_v_degree": None,
  "X_train": [(v1, v2), ...] unnconnected vertex pairs until 2016,
  "y_train": [0, 1, 1, 0, ...] indicating whether the vertex pairs will be connected in 2016 + 3 (year_delta),
  "X_test": [(v1, v2), ...] unnconnected vertex pairs until 2019,
  "y_test": whether the vertex pairs will be connected in 2022,
}
```

## How to add new model

The classification process can typically be divided into two steps:

1. Generate embeddings for node pairs
2. Train a (binary) classifier on the embeddings

## Example: Baseline Model

1. Generate the embeddings

```
python model/baseline/create_embeddings.py \
 --graph_path data/graph/edges.pkl \
 --data_path data/model/data.pkl \
 --output_path data/model/baseline/embeddings.pkl \
 --include_jaccard False
```

2. Train the model

```
python model/baseline/train.py \
  --data_path data/model/data.pkl \
  --embeddings_path data/model/baseline/embeddings.pkl \
  --lr 0.001 \
  --batch_size 100 \
  --num_epochs 1 \
  --train_model True \
  --save_model data/model/baseline/model.pt \
  --metrics_path data/model/baseline/metrics.pkl \
  --eval_mode False
```

# Word Embeddings

## Generate Word Embeddings

Word embeddings are generated using BERT or a fine-tuned version of BERT e.g. MatSciBERT.
To extract ambeddings for all concepts (all embedded tokens comprising a concept are `averaged`), run:

```
python word_embeddings/generate.py \
  --concepts_path data/table/materials-science.llama.works.csv \
  --lookup_path data/table/lookup/lookup_large.csv \
  --output_path data/embeddings/large/ \
  --log_to_stdout False \
  --step_size 500 \
  --start 0 \
  --end 750000
```

> Currently, if a concept is not exactly contained in the abstract (this can happen because LLMs can apply some "normalization" during extraction), the embedding vector is set to the average of all tokens in the abstract.
> On GPU4_A100 generating embeddings for 80k abstracts takes about 6h.

## Average Word Embeddings

Averaging word (concept) embeddings so that they can be used as feature vectors for classification.

```
python word_embeddings/average_embs.py \
  --concepts_path data/table/materials-science.llama.works.csv \
  --lookup_path data/table/lookup/lookup_large.csv \
  --filter_path data/table/lookup/lookup_small.csv \
  --embeddings_dir data/embeddings/large/ \
  --output_path data/model/concept_embs/av_embs_small_2016.pkl.gz \
  --store_concepts_plain False \
  --until_year 2016
```

## Train MLP

```
python model/concept_embs/train.py \
  --data_path data/model/data.pkl \
  --emb_train_path data/model/concept_embs/av_embs_2016.pkl.gz \
  --emb_test_path data/model/concept_embs/av_embs_2019.pkl.gz \
  --lr 0.001 \
  --batch_size 100 \
  --num_epochs 1 \
  --train_model True \
  --save_model data/model/concept_embs/model.pt \
  --metrics_path data/model/concept_embs/metrics.pkl \
  --pos_to_neg_ratio 0.03 \
  --input_dim 1536 \
  --eval_mode False
```

## Train GNN

# TODO General

## Process

- [x] Create README with instructions to recreate progress
- [x] Implement cursor fetching
- [x] Work cleaning: Filter out works (no title, no abstract, retracted, paratext, english lang)
- [x] Abstract cleaning: Clean chemical elements
- [ ] Invert filenames: ...cleaned.works.csv -> ...works.cleaned.csv
- [x] Add title to abstract (before cleaning)
- [x] Generate cleaned 'list' of all concepts
  - [x] Rake
  - [x] LLM
    - [x] Get access to BWUniCluster
    - [x] Annotate 100 abstracts with concepts
    - [x] Fine-tune LLM
    - [x] Inference: extract concepts from all abstracts
- [x] Build graph with histogram edges
  - [x] Start with reduced concept list (keep concepts n>1) and discard materials where an element appears twice
- [x] Implement Baseline
- [x] Implement evaluation (on test set)
- [x] Implement validation (on future data)
- [x] Implement top performing model from kaggle challange (More or less)
- [x] Store model and graph
- [x] Extract concept embeddings (Calculate storage requirements)
- [ ] Build Baseline (Features + Embeddings)

  - [ ] Resturct Trainloop
    - [ ] One epoch: sample batchsize / 2 positive and batchsize / 2 negative samples
    - [ ] Generalize Model architecture with params: LR, #Layers, Layer degradation, Initial hidden state
    - [ ] Trainloop: with early stopping and eval on every ith epoch on test set
  - [ ] Generate embeddings "on the fly", just store the squared adjacency matrix

- [ ] Build API to query prediction service
- [ ] Build Tiny Frontend
  - [ ] Build Search Bar
  - [ ] Input: Concept (with Suggestions) -> Output: future synergies (ranked, k=10)
  - [ ] Every researcher is a subgraph, calculate collaboration in O(C1 \* C2) where C1 and C2 are the number of concepts of the researchers. Highest ranked concept combinations are the most promising collaborations.

## Optimization

- [x] Where to store the data? (-> Device)
- [x] Data storing for works: How to store concepts (fetched and generated)
- [x] How to speed up text processing in pandas? Pandas 2.0 (x) or other option to achieve pyarrow backend
- [ ] Dockerize what comes after data fetching
- [ ] How to optimize "concept synergy" query for concept v? (Naive: `O(n * pred(x,v))`)
  - [ ] Caching: Precalculate and store
  - [ ] Online Algorithm: Enter new concept (Get embeddings, likely to work better if word embeddings are used in addition)

# My handy tools

## Abstract checking

Retrieve abstract for work given work ID: `$ abstract W2159161622`

## Identifying Sourcce

Retrieve source for work given work ID: `$ getsource W2159161622`

```

```

```

```

```

```
